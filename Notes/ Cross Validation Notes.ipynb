{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: Why use train and test data?\n",
    "- gives estimate of performance on new dataset\n",
    "- serves as check on over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Transform, and Predicting Process\n",
    "1) train test split\n",
    "2) pca\n",
    "3) svm (or other method)\n",
    "\n",
    "#### Flow:\n",
    "1) pca.fit(train features)\n",
    "\n",
    "2) train features = pca.transform(train features)\n",
    "\n",
    "3) svc.train(train features)\n",
    "\n",
    "4) test features = pca.transform(test features)\n",
    "\n",
    "5) pred = svc.predict(test features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation\n",
    "\n",
    "#### Problems with splitting testing and training data:\n",
    "- trade-off between the amount of data to train vs. to test\n",
    "\n",
    "#### Solultion: partition data in k-bins of same amount\n",
    "- run k-separate experiments \n",
    "- pick test set \n",
    "- train\n",
    "- test on testing set\n",
    "- max accuracy\n",
    "\n",
    "##### Tradeoff- can be expensive, train/test split is quicker, min run train time\n",
    "\n",
    "## in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a simple way to randomize the events in sklearn k-fold CV: set the shuffle flag to true.\n",
    "\n",
    "Then you'd go from something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = model_selection.KFold( len(authors), 2 , shuffle = True)\n",
    "# 1: number of items total in dataset\n",
    "# 2. how many folds to look at\n",
    "\n",
    "#To something like this:\n",
    "\n",
    "cv = KFold( len(authors), 2, shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gives 2 lists:\n",
    "1) indices to use in test set\n",
    "\n",
    "2) indices to use in train set\n",
    "\n",
    "Implementation would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_indices, test_indices in cv:\n",
    "    features_train = [word[ii] for ii in train_indices]\n",
    "    features_test = [word[ii] for ii in test_indices]\n",
    "    labels_train = [labels[ii] for ii in train_indices]\n",
    "    labels_test = [labels[ii] for ii in test_indices]\n",
    "    \n",
    "    print(train_indices)\n",
    "    print(labels_train)\n",
    "    print(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: can get errors if data has imbalanced class or is not randomized\n",
    "ex: labels in first half of dataset, then none is second half\n",
    "\n",
    "To fix this, we add the shuffle paramter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = KFold( len(authors), 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV is way of systematically working through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance. It can work through many combinations in only a couple extra lines of code (thanks udacity!)\n",
    "\n",
    "sklearn example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary of the parameters, and the possible values they may take. In this case, they're playing around with the kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a 'grid' of all the following combinations of values for (kernel, C) are automatically generated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each is used to train an SVM, and the performance is then assessed using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks kind of like creating a classifier, just like we've been doing since the first lesson. But note that the \"clf\" isn't made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying around with the kernel or C; all that is handled in the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = grid_search.GridSearchCV(svr, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier is being created. We pass the algorithm (svr) and the dictionary of parameters to try (parameters) and it generates a grid of parameter combinations to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function now tries all the parameter combinations, and returns a fitted classifier that's automatically tuned to the optimal parameter combination.\n",
    "\n",
    "You can now access the parameter values via: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
