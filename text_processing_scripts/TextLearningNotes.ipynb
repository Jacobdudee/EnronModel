{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Learning Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words model\n",
    "\n",
    "#### Goal: Find word frequency counts\n",
    "\n",
    "\n",
    "#### Questions:\n",
    "1. Does the word order matter inside a phrase? No\n",
    "2. Do long phrases give different input vectors? Yes\n",
    "3. Can we have complex phrases? \"Chicago Bulls\" no\n",
    "\n",
    "#### Bag of Words in SKLearn aka CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t3\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t2\n",
      "  (1, 10)\t1\n"
     ]
    }
   ],
   "source": [
    "data = ['this is a long string string string and a test',\n",
    "        'also this is a test test string great learning much fun']\n",
    "bag_of_words = Vectorizer.fit(data)\n",
    "bag_of_words = Vectorizer.transform(data)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get the document number of the left of the tuple, and the word in the right of the tuple. The frequency count is in the column outside of the tuple.\n",
    "\n",
    "This gets you the feature number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "word = 'string'\n",
    "print Vectorizer.vocabulary_.get(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not all words have equal amount of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some just have more information than others\n",
    "    - so must remove, to get rid of noise\n",
    "    \n",
    "Called <b/>Stopwords</b>!\n",
    "    - the, a, will, in, for,you,be etc.\n",
    "    \n",
    "<b/>Can import from NLTK library:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to specify language\n",
    "sw = stopwords.words('English')\n",
    "len(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem: not all unique words are different\n",
    "- Word meaning changes based on context, ex: responsiveness,responsive\n",
    "\n",
    "#### Solution: word stemmer\n",
    "- stemmer ex: responsive ---> respons\n",
    "- take stemmers off shelf and make use of it\n",
    "- results in much cleaner vocabulary\n",
    "\n",
    "#### Stemming with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dont forget to specify language\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'respons'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"responsiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'unrespons'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"unresponsive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to fine-tune and specify goals of project to stem as efficient as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of operations in text processing\n",
    "\n",
    "1) Stemming\n",
    "\n",
    "2) bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Representation\n",
    "\n",
    "#### Key Terms:\n",
    "- TF: term frequency (bag of words)\n",
    "- IDF: inverse document frequency\n",
    "\n",
    "#### Idea:\n",
    "\n",
    "Weight words by how often they occur in the corpus (whole text)\n",
    "    - Weights rare words higher because of greater id of important messages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = pd.read_pickle(\"your_word_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'jtownsensf httpgasmsgboardcorpenroncom '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
