{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Accuracy\n",
    "- number of items that are labeled correctly that are predicted to be member of class/#members in class\n",
    "\n",
    "##### What are some shortcomings of accuracy?\n",
    "- perhaps not ideal for skewed class (small amount of outcomes/classes)\n",
    "- may want to tune for certain outcomes (ex: not assume someone is guilty, so err on guessing innocent)\n",
    "\n",
    "<b/> So accuracy is a problem when you have skewed classes. <b/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "- measures predicted classes vs. actual classes\n",
    "- gets true positive rate (Recall)\n",
    "- gets true negative rate ()\n",
    "- false positive rate (Type I Error)\n",
    "- false negative rate (Type II Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.0/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20+63+36+127+26+16+34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049689440993788817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/322.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall: probability that algorithm correctly ids class provided that the class is the predicted class\n",
    "- ex: probability that the algorithm correctly Hugo Chavez labeled images\n",
    "- calculate by getting accurate results/total labels across columns in confusion matrix\n",
    "\n",
    "#### Recall Calculation: (# true positives) / (# true positives + # false negatives)\n",
    "\n",
    "## Precision: rate of chances that guess some class that it actually is class \n",
    "- ex: probability that the algorithm guesses Hugo Chavez that it actually is Hugo Chavez\n",
    "- calculate by counting accurate guesses / number of guesses in class\n",
    "- calculate moving down column\n",
    "\n",
    "#### Precision Calculation: (# true postives)/(# true positives + # false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55/63.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208955223880597"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55/67.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968503937007874"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123.0/127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884615384615384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123.0/156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25.0/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Enron POI identifier, I think that a proper metric to maximize would be recall, as most the of the big dogs are going to be identified anyway in the investigation, so this algorithm should be tuned to get people that might not be id'd as POI in the investigation. The trade-off is that people who aren't POI are identified as such, but it is worth it when you consider the crimes Enron committed. \n",
    "\n",
    "## F1 Score: considers both recall and precision in calculation\n",
    "\n",
    "#### The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. [wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "https://en.wikipedia.org/wiki/F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
